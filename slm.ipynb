{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sparshpatel/opt/anaconda3/envs/slm_env/lib/python3.9/site-packages/ebooklib/epub.py:1395: UserWarning: In the future version we will turn default option ignore_ncx to True.\n",
      "  warnings.warn('In the future version we will turn default option ignore_ncx to True.')\n",
      "/Users/sparshpatel/opt/anaconda3/envs/slm_env/lib/python3.9/site-packages/ebooklib/epub.py:1423: FutureWarning: This search incorrectly ignores the root element, and will be fixed in a future version.  If you rely on the current behaviour, change it to './/xmlns:rootfile[@media-type]'\n",
      "  for root_file in tree.findall('//xmlns:rootfile[@media-type]', namespaces={'xmlns': NAMESPACES['CONTAINERNS']}):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "index\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Contents \n",
      "Chapter One ....................................................................................................................................... 1 \n",
      "Chapter Two ........................................................................................................................................ 8 \n",
      "Chapter Three ................................................................................................................................... 14 \n",
      "Chapter Four ..................................................................................................................................... 21 \n",
      "Chapter Five ..................................................................................................................................... 26 \n",
      "Chapter Six ....................................................................................................................................... 30 \n",
      "Chapter Seven ....................................................\n"
     ]
    }
   ],
   "source": [
    "# Step 1:\n",
    "import ebooklib\n",
    "from ebooklib import epub\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_text_from_epub(epub_path):\n",
    "    book = epub.read_epub(epub_path)\n",
    "    text = \"\"\n",
    "    \n",
    "    for item in book.get_items():\n",
    "        if item.get_type() == ebooklib.ITEM_DOCUMENT:\n",
    "            soup = BeautifulSoup(item.content, 'html.parser')\n",
    "            text += soup.get_text() + \"\\n\\n\"\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Example Usage\n",
    "epub_path = \"/Users/sparshpatel/Documents/Codes/codes/pythonml/slm/Percy Jackson and the Olympians 5 - The Last Olympian by Rick Riordan (z-lib.org).epub\"  # Replace with your actual file\n",
    "book_text = extract_text_from_epub(epub_path)\n",
    "print(book_text[:1000])  # Print a sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/sparshpatel/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks: 514\n",
      "['Beckendorf chuckled, and together we soared out over the Atlantic. It was almost dark by the time we spotted our target. The  Princess Andromeda  glowed on \\n3 \\nthe horizon—a huge cruise ship lit up yellow and white. From a distance, you\\'d think it was just a \\n3\\nparty ship, not the headquarters for the Titan lord. Then as you got closer, you might notice the giant \\nfigurehead—a dark-haired maiden in a Greek chiton, wrapped m chains with a look of horror on her \\nface, as if she could smell the stench of all the monsters she was being forced to carry. Seeing the ship again twisted my gut into knots. I\\'d almost died twice on the  Princess \\nAndromeda. Now it was heading straight for New York. \"You know what to do?\" Beckendorf yelled over the wind. I nodded. We\\'d done dry runs at the dockyards in New Jersey, using abandoned ships as \\nour targets. I knew how little time we would have. But I also knew this was our best chance to end \\nKronos\\'s invasion before it ever started.', '\"Blackjack,\" I said, \"set us down on the lowest stern deck.\" Gotcha, boss,  he said. Man, I hate seeing that boat. Three years ago, Blackjack had been enslaved on the  Princess Andromeda  until he\\'d \\nescaped with a little help from my friends and me. I figured he\\'d rather have his mane braided like \\nMy Little Pony than be back here again. \"Don\\'t wait for us,\" I told him. But, boss—  \\n\"Trust me,\" I said. \"We\\'ll get out by ourselves.\" Blackjack folded his wings and plummeted toward the boat like a black comet. The wind \\nwhistled in my ears. I saw monsters patrolling the upper decks of the ship— dracaenae snakewomen, hellhounds, giants, and the humanoid seal-demons known as telkhines—but we zipped by \\nso fast, none of them raised the alarm. We shot down the stern of the boat, and Blackjack spread \\nhis wings, lightly coming to a landing on the lowest deck. I climbed off, feeling queasy. Good luck, boss,  Blackjack said. Don\\'t let \\'em turn you into horse meat! With that, my old friend flew off into the night.', 'I took my pen out of my pocket and uncapped \\nit, and Riptide sprang to full size—three feet of deadly Celestial bronze glowing in the dusk. Beckendorf pulled a piece of paper out of his pocket. I thought it was a map or something. Then I realized   it was a photograph. He stared at it in the dim light—the smiling face of Silena \\nBeauregard, daughter of Aphrodite. They\\'d started going out last summer, after years of the rest of \\nus saying, \"Duh, you guys like each other!\" Even with all the dangerous missions, Beckendorf had \\nbeen happier this summer than I\\'d ever seen him. \"We\\'ll make it back to camp,\" I promised. For  a  second I saw worry in his eyes. Then he put on his old confident smile. \"You bet,\" he said. \"Let\\'s go blow Kronos back into a million pieces.\" Beckendorf led the way. We followed a narrow corridor to the service stairwell, just like we\\'d \\npracticed, but we froze when we heard noises above us. \"I don\\'t care what your nose says!\" snarled a half-human, half-dog voice—a telkhine.', '\"The \\nlast time you smelled half-blood, it turned out to be a meat loaf sandwich!\" \"Meat loaf sandwiches are good!\" a second voice snarled. \"But this is half-blood scent, I \\nswear. They are on board!\" \"Bah, your  brain  isn\\'t on board!\" They continued to argue, and Beckendorf pointed downstairs. We descended as quietly as \\nwe could. Two floors down, the voices of the telkhines started to fade. Finally we came to a metal hatch. Beckendorf mouthed the words \"engine room.\" It was locked, but Beckendorf pulled some chain cutters out of his bag and split the bolt like \\nit was made of butter. Rick Riordan\\n \\nThe Last Olympian - 05\\nInside, a row of yellow turbines the size of grain silos churned and hummed. Pressure \\ngauges and computer terminals lined the opposite wall. A telkhine was hunched over a console, but \\nhe was so involved with his work, he didn\\'t notice us. He was about five feet tall, with slick black \\nseal fur and stubby little feet. He had the head of a Doberman, but his clawed hands were almost \\nhuman.', 'He growled and muttered as he tapped on his keyboard. Maybe he was messaging his \\nfriends on uglyface.com. I stepped forward, and he tensed, probably smelling something was wrong. He leaped \\nsideways toward a big red alarm button, but I blocked his path. He hissed and lunged at me, but \\n4\\none slice of Riptide, and he exploded into dust. \"One down,\" Beckendorf said. \"About five thousand to go.\" He tossed me a jar of thick green \\nliquid—Greek fire, one of the most dangerous magical substances in the world. Then he threw me \\nanother essential tool of demigod heroes—duct tape. \"Slap that one on the console,\" he said. \"I\\'ll get the turbines.\" We went to work. The room was hot and humid, and in no time we were drenched m sweat. The boat kept chugging along. Being the son of Poseidon and all, I have perfect bearings at \\nsea. Don\\'t ask me how, but I could tell we were at 40.19° North, 71.90° West, making eighteen \\nknots, which meant the ship would arrive in New York Harbor by dawn.']\n"
     ]
    }
   ],
   "source": [
    "# Step 2:\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "# Download necessary NLTK data\n",
    "nltk.download('punkt')\n",
    "\n",
    "def split_into_chunks(text, max_chunk_size=1024):\n",
    "    sentences = sent_tokenize(text)  # Split into sentences\n",
    "    chunks = []\n",
    "    chunk = \"\"\n",
    "\n",
    "    for sentence in sentences:\n",
    "        if len(chunk) + len(sentence) <= max_chunk_size:\n",
    "            chunk += sentence + \" \"\n",
    "        else:\n",
    "            chunks.append(chunk.strip())\n",
    "            chunk = sentence + \" \"\n",
    "\n",
    "    if chunk:\n",
    "        chunks.append(chunk.strip())\n",
    "\n",
    "    return chunks\n",
    "\n",
    "# Apply chunking\n",
    "chunks = split_into_chunks(book_text)\n",
    "print(f\"Total chunks: {len(chunks)}\")\n",
    "print(chunks[10:15])  # Print first 3 chunks for verification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/sparshpatel/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks: 508\n",
      "['', 'index Contents Chapter One ....................................................................................................................................... 1 Chapter Two ........................................................................................................................................ 8 Chapter Three ................................................................................................................................... 14 Chapter Four ..................................................................................................................................... 21 Chapter Five ..................................................................................................................................... 26 Chapter Six ....................................................................................................................................... 30 Chapter Seven .................................................................................................................................. 37 Chapter Eight .................................................................................................................................... 44 Chapter Nine ..................................................................................................................................... 49 Chapter Ten ...................................................................................................................................... 57 Chapter Eleven ................................................................................................................................. 63 Chapter Twelve ................................................................................................................................. 68 Chapter Thirteen ............................................................................................................................... 75 Chapter Fourteen .............................................................................................................................. 80 Chapter Fifteen ................................................................................................................................. 89 Chapter Sixteen ................................................................................................................................ 96 Chapter Seventeen ......................................................................................................................... 104 Chapter Eighteen ............................................................................................................................ 109 Chapter Nineteen .............................................................................................................................112 Chapter Twenty ................................................................................................................................119 Chapter Twenty-One ....................................................................................................................... 125 Chapter Twenty-Two ....................................................................................................................... 127 Chapter Twenty-Three .................................................................................................................... 132 Percy Jackson and the Olympians Chapter One I Go Cruising With Explosives The end of the world started when a pegasus landed on the hood of my car.', '1 Up until then, I was having a great afternoon. Technically I wasn\\'t supposed to be driving 1 because I wouldn\\'t turn sixteen for another week, but my mom and my stepdad, Paul, took my friend Rachel and me to this private stretch of beach on the South Shore, and Paul let us borrow his Prius for a short spin. Now, I know you\\'re thinking, Wow, that was really irresponsible of him, blah, blah, blah, but Paul knows me pretty well. He\\'s seen me slice up demons and leap out of exploding school buildings, so he probably figured taking a car a few hundred yards wasn\\'t exactly the most dangerous thing I\\'d ever done. Anyway, Rachel and I were driving along. It was a hot August day. Rachel\\'s red hair was pulled back in a ponytail and she wore a white blouse over her swimsuit. I\\'d never seen her in anything but ratty T-shirts and paint-splattered jeans before, and she looked like a million golden drachmas. \"Oh, pull up right there!\" she told me. We parked on a ridge overlooking the Atlantic.', 'The sea is always one of my favorite places, but today it was especially nice—glittery green and smooth as glass, as though my dad was keeping it calm just for us. My dad, by the way, is Poseidon. He can do stuff like that. \"So.\" Rachel smiled at me. \"About that invitation.\" \"Oh . . . right.\" I tried to sound excited. I mean, she\\'d asked me to her family\\'s vacation house on St. Thomas for three days. I didn\\'t get a lot of offers like that. My family\\'s idea of a fancy vacation was a weekend in a rundown cabin on Long Island with some movie rentals and a couple of frozen pizzas, and here Rachel\\'s folks were willing to let me tag along to the Caribbean. Besides, I seriously needed a vacation. This summer had been the hardest of my life. The idea of taking a break even for a few days was really tempting. Still, something big was supposed to go down any day now. I was \"on call\" for a mission. Even worse, next week was my birthday. There was this prophecy that said when I turned sixteen, bad things would happen.', '\"Percy,\" she said, \"I know the timing is bad. But it\\'s always bad for you, right?\" She had a point. \"I really want to go,\" I promised. \"It\\'s just—\" \"The war.” I nodded. I didn\\'t like talking about it, but Rachel knew. Unlike most mortals, she could see through the Mist—the magic veil that distorts human vision. She\\'d seen monsters. She\\'d met some of the other demigods who were fighting the Titans and their allies. She\\'d even been there last summer when the chopped-up Lord Kronos rose out of his coffin in a terrible new form, and she\\'d earned my permanent respect by nailing him in the eye with a blue plastic hairbrush. She put her hand on my arm. \"Just think about it, okay? We don\\'t leave for a couple of days. My dad . . .\" Her voice faltered. \"Is he giving you a hard time?\" I asked. Rachel shook her head in disgust. \"He\\'s trying to be nice to me, which is almost worse. He wants me to go to Clarion Ladies Academy m the fall.\" \"The school where your mom went?\"']\n"
     ]
    }
   ],
   "source": [
    "# Another way to categorise chunks, may lead to different answers\n",
    "# import re\n",
    "# import nltk\n",
    "# from nltk.tokenize import sent_tokenize\n",
    "\n",
    "# # Download necessary NLTK data\n",
    "# nltk.download('punkt')\n",
    "\n",
    "# def clean_text(text):\n",
    "#     \"\"\"Removes excessive newlines while preserving structure and removes standalone author mentions.\"\"\"\n",
    "#     text = re.sub(r'\\n+', '\\n', text)  # Replace multiple newlines with a single one\n",
    "#     text = re.sub(r'\\bRick Riordan\\b(?!\\w)', '', text, flags=re.IGNORECASE)  # Remove only standalone \"Rick Riordan\"\n",
    "#     text = re.sub(r'\\s+', ' ', text).strip()  # Normalize spaces\n",
    "#     return text\n",
    "\n",
    "# def split_into_chunks(text, max_chunk_size=1024):\n",
    "#     text = clean_text(text)  # Clean text before chunking\n",
    "#     sentences = sent_tokenize(text)  # Split into sentences\n",
    "#     chunks = []\n",
    "#     chunk = \"\"\n",
    "\n",
    "#     for sentence in sentences:\n",
    "#         if len(chunk) + len(sentence) <= max_chunk_size:\n",
    "#             chunk += sentence + \" \"\n",
    "#         else:\n",
    "#             chunks.append(chunk.strip())\n",
    "#             chunk = sentence + \" \"\n",
    "\n",
    "#     if chunk:\n",
    "#         chunks.append(chunk.strip())\n",
    "\n",
    "#     return chunks\n",
    "\n",
    "# # Apply cleaning and chunking\n",
    "# cleaned_text = clean_text(book_text)\n",
    "# chunks = split_into_chunks(cleaned_text)\n",
    "\n",
    "# print(f\"Total chunks: {len(chunks)}\")\n",
    "# print(chunks[:5])  # Print first 5 chunks for verification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3:\n",
    "chunks = [chunk for chunk in chunks if chunk.strip()]  # Remove empty or whitespace-only chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sparshpatel/opt/anaconda3/envs/slm_env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Step 4:\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"sentence-transformers/all-mpnet-base-v2\")  # Higher accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunks successfully embedded!\n"
     ]
    }
   ],
   "source": [
    "# Step 5:\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "# Load the same model we used before\n",
    "model = SentenceTransformer(\"sentence-transformers/all-mpnet-base-v2\")\n",
    "\n",
    "# Convert text chunks into embeddings\n",
    "chunk_embeddings = model.encode(chunks, convert_to_tensor=True)\n",
    "\n",
    "print(\"Chunks successfully embedded!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6:\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load the embedding model\n",
    "embedding_model = SentenceTransformer(\"sentence-transformers/all-mpnet-base-v2\")\n",
    "\n",
    "# Encode the chunks\n",
    "chunk_embeddings = embedding_model.encode(chunks, convert_to_tensor=True)  # Returns a PyTorch tensor\n",
    "chunk_embeddings = chunk_embeddings.cpu().numpy()  # Move to CPU and convert to NumPy\n",
    "\n",
    "# Now rebuild the FAISS index\n",
    "import faiss\n",
    "index = faiss.IndexFlatL2(chunk_embeddings.shape[1])  \n",
    "index.add(chunk_embeddings)  # No more errors!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7:\n",
    "import faiss\n",
    "index = faiss.IndexFlatL2(chunk_embeddings.shape[1])\n",
    "index.add(chunk_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8:\n",
    "from torch.nn.functional import cosine_similarity\n",
    "import torch\n",
    "\n",
    "def find_best_chunk(question):\n",
    "    # Encode the question\n",
    "    question_embedding = model.encode(question, convert_to_tensor=True)\n",
    "    \n",
    "    # Compute similarity with all chunks\n",
    "    similarities = cosine_similarity(question_embedding, chunk_embeddings)\n",
    "    \n",
    "    # Get the index of the most relevant chunk\n",
    "    best_chunk_idx = torch.argmax(similarities).item()\n",
    "    \n",
    "    return chunks[best_chunk_idx]  # Return the most relevant chunk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "# Step 9:\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load the Question Answering pipeline\n",
    "qa_pipeline = pipeline(\"question-answering\", model=\"deepset/roberta-base-squad2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hades\n"
     ]
    }
   ],
   "source": [
    "# Step 10:\n",
    "def retrieve_best_chunk(question):\n",
    "    question_embedding = embedding_model.encode([question], convert_to_numpy=True)\n",
    "    _, indices = index.search(question_embedding, 1)\n",
    "    return chunks[indices[0][0]]\n",
    "\n",
    "def answer_question(question):\n",
    "    best_chunk = retrieve_best_chunk(question)\n",
    "    result = qa_pipeline(question=question, context=best_chunk)\n",
    "    return result[\"answer\"]\n",
    "\n",
    "question = \"Who is the god of underworld??\"\n",
    "print(answer_question(question))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "slm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
